# ğŸŒ¾ Agri-Meteo Big Data Pipeline

Pipeline **Big Data / ETL** pour collecter, transformer et analyser des donnÃ©es mÃ©tÃ©orologiques, produisant des **indicateurs dÃ©cisionnels exploitables** pour l'agriculture, l'Ã©nergie et l'environnement.

---

## ğŸ¯ Vision MÃ©tier

Les donnÃ©es mÃ©tÃ©orologiques sont souvent dispersÃ©es, volumineuses et difficiles Ã  exploiter. Ce projet fournit une **chaÃ®ne de traitement complÃ¨te** transformant les donnÃ©es brutes en **KPI clairs**, prÃªts pour la Business Intelligence.

---

## ğŸ§  Architecture ETL

```
API / CSV
    â†“
Python (Extract)
    â†“
PySpark (Transform)
    â†“
Parquet / PostgreSQL
    â†“
Dashboard BI
```

**1. Extract** â€“ Collecte automatisÃ©e via API  
**2. Transform** â€“ Nettoyage et agrÃ©gation avec PySpark  
**3. Load** â€“ Stockage optimisÃ© (Parquet + PostgreSQL)  
**4. Exploitation** â€“ Visualisation BI (Power BI, Tableau)

---

## ğŸ› ï¸ Stack Technique

- **Python** â€“ Orchestration
- **PySpark** â€“ Traitement distribuÃ©
- **PostgreSQL** â€“ Base de donnÃ©es
- **Docker & Docker Compose** â€“ DÃ©ploiement
- **Parquet** â€“ Format optimisÃ©
- **Power BI / Tableau** â€“ Visualisation

---

## ğŸ“Š Indicateurs Produits

- TempÃ©rature moyenne par pÃ©riode
- Cumul des prÃ©cipitations
- Tendances saisonniÃ¨res
- CorrÃ©lations mÃ©tÃ©o-agricoles

---

## ğŸ“ Structure du Projet

```
agri-meteo-bigdata-pipeline/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # DonnÃ©es brutes
â”‚   â””â”€â”€ processed/        # DonnÃ©es transformÃ©es
â”‚
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ agri_meteo_etl.py
â”‚   â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ plugins/
â”‚   â””â”€â”€ docker-compose.airflow.yml

â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract.py        # Extraction API
â”‚   â”œâ”€â”€ transform.py      # Transformation 
â”‚   â””â”€â”€ load.py           # Chargement vers DB / Parquet
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb # Analyse exploratoire
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ screenshots/      # Visualisations
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml        # Spark + Postgres mÃ©tier
â”‚   â”œâ”€â”€ docker-compose.airflow.yml
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml       # Configuration
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ğŸ³ Installation avec Docker (RecommandÃ©)

### 1ï¸âƒ£ Cloner le projet

```bash
git clone https://github.com/biko2020/agri-meteo-bigdata-pipeline.git
cd agri-meteo-bigdata-pipeline
```

### 2ï¸âƒ£ DÃ©marrer l'environnement

```bash
docker compose up -d
docker ps
```

### 3ï¸âƒ£ ExÃ©cuter le pipeline

```bash
# AccÃ©der au conteneur Spark
docker exec -it spark bash

# 1. Extraction
python3 /app/scripts/extract.py

# 2. Transformation et Nettoyage et calculs massifs  (PySpark)
spark-submit /app/scripts/transform.py

# 3. Chargement
python3 /app/scripts/load.py
```

### 4ï¸âƒ£ AccÃ©der Ã  Spark UI

```
http://localhost:8081
```

---

## ğŸ’¼ Cas d'Usage Professionnels

Ce pipeline est directement applicable pour :

- CrÃ©ation de pipelines ETL production
- Traitement de donnÃ©es volumineuses (Big Data)
- Migration CSV/Excel vers bases de donnÃ©es
- PrÃ©paration de donnÃ©es pour dashboards BI
- Projets Data Engineering / Data Science

---

## ğŸ“¦ DÃ©pendances Python

```
pyspark
pandas
requests
pyyaml
sqlalchemy
psycopg2-binary
```

---

##  Contact

**AIT OUFKIR BRAHIM**  
Data Engineer / Big Data Developer

-  Email : aitoufkirbrahimab@gmail.com
-  GitHub : [github.com/biko2020](https://github.com/biko2020/agri-meteo-bigdata-pipeline)
